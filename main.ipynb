{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3c9c8a-cac1-4089-9d40-5212ad779d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "np.random.seed(42)\n",
    "emotions = ['happy', 'surprise', 'sad', 'angry', 'disgust', 'fear', 'neutral']\n",
    "predictions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab7c327-f9d7-47c6-b7d7-adfbd377cfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['fer2013', 'rafdb']\n",
    "#datasets = ['fer2013']\n",
    "#datasets = ['rafdb']\n",
    "\n",
    "#modelp = 'resemotenet'\n",
    "modelp = 'vit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0b556f-d233-45b8-aa6c-c56a9c106848",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX = 150\n",
    "for dataset in datasets:\n",
    "    print('ds:', dataset)\n",
    "    classes = []\n",
    "    preds = []\n",
    "    shaps = []\n",
    "    weights = os.path.join(os.getcwd(), 'datasets', dataset+'_model_'+modelp+'.pth')\n",
    "    for label in emotions:\n",
    "        print('label:', label)\n",
    "        files = np.array( list(sorted(os.listdir(os.path.join(os.getcwd(), 'datasets', dataset, 'test', label)), reverse=True) ))\n",
    "        idxs = np.arange(len(files))\n",
    "        idxs = shuffle(idxs, random_state=42) \n",
    "        files = files[idxs]\n",
    "        c = 0\n",
    "        for file_ in files:\n",
    "            img = cv2.imread(os.path.join(os.getcwd(), 'datasets', dataset, 'test', label, file_))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(img) \n",
    "\n",
    "            pred, model = detect_emotion(img, weights, modelp, emotions, True)                \n",
    "            classes.append(emotions.index(label))\n",
    "            preds.append(pred)\n",
    "            del pred\n",
    "\n",
    "            if c<MAX:\n",
    "                preds_aux = {}\n",
    "                shap_values, probs, imgs = generate_shap_images(img, model, modelp, device, emotions)\n",
    "                for key in imgs:\n",
    "                    pred = detect_emotion(imgs[key], weights, modelp, emotions) \n",
    "                    preds_aux[key] = pred\n",
    "                    del pred\n",
    "                if (c%10)==0:\n",
    "                    shaps.append([label, shap_values.values[0].astype(np.float16), probs, img, imgs, preds_aux])\n",
    "                else:\n",
    "                    shaps.append([label, shap_values.values[0].astype(np.float16), probs, None, None, preds_aux])\n",
    "                del preds_aux \n",
    "            c+=1\n",
    "\n",
    "    with open(os.path.join(os.getcwd(), 'out', modelp+'_shaps_'+dataset+'.pkl'), 'wb') as a:\n",
    "        pickle.dump(shaps, a, protocol=2)\n",
    "    with open(os.path.join(os.getcwd(), 'out', modelp+'_results_'+dataset+'.pkl'), 'wb') as a:\n",
    "        pickle.dump([classes, preds], a, protocol=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py311)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
